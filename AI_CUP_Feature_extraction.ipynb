{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp7ImTx+YBM2Anf0O4T51e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nusha34/AI_CUP/blob/main/AI_CUP_Feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from dataset import Dataset"
      ],
      "metadata": {
        "id": "nWyPOHKU2VOC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset('train.csv', frequency= \"D\", window_size= 7)"
      ],
      "metadata": {
        "id": "szhGzoiJ3BNi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Fc2RBq3gGD",
        "outputId": "10793a83-e702-4ba5-a04c-8aeec8d3b82d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<dataset.Dataset at 0x7fd1ffb506d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    \"\"\"\n",
        "    Dataset class. Loads consumption and weather data per household group\n",
        "    Args:\n",
        "    window_size : No of historical days to include in the window\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 df_path: float,\n",
        "                 frequency: str = \"D\",  # change to \"H\" for second subtask\n",
        "                 window_size: int = 7,\n",
        "                 n_rows: int = 100,\n",
        "                 ids: bool = True,\n",
        "                 **kwargs) -> None:\n",
        "\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        self.path = df_path\n",
        "        self.nrows = n_rows\n",
        "        self.window_size = window_size\n",
        "        self.data = pd.read_csv(os.path.join(os.getcwd(), \"\", self.path))\n",
        "        if ids:\n",
        "            self.data.set_index(self.data.pseudo_id, drop=True, inplace=True)\n",
        "            self.data.drop(columns='pseudo_id', inplace=True)\n",
        "\n",
        "        self.data.columns = [dt.datetime.strptime(c, \"%Y-%m-%d %H:%M:%S\") for c in self.data.columns]\n",
        "        self.ids = self.data.index\n",
        "        # self.data = self.data.T[self.data.T.index <= self.weather['min'].index[-1]]\n",
        "        if frequency == \"D\":\n",
        "            self.freq = frequency\n",
        "            self.data = self.data.T.groupby(self.data.T.index.date).sum().T\n",
        "        else:\n",
        "            self.freq = \"H\"\n",
        "            self.data = self.data.T.resample(self.freq).sum().T\n",
        "\n",
        "    def get_test_idx(self) -> object:\n",
        "        return pd.date_range(start='2017-01-01', end='2019-03-31', freq= self.freq).difference(self.data.T.index)\n",
        "\n",
        "    def create_lag(self, target, lags=1, thres=0.2):\n",
        "        \"\"\"Creates lag features of length window_size\"\"\"\n",
        "        # init scaler\n",
        "        scaler = StandardScaler()\n",
        "        df = pd.DataFrame()\n",
        "        if 0 in lags:\n",
        "            lags.remove(0)\n",
        "        for l in lags:\n",
        "            df[f\"lag_{l}\"] = target.shift(l)\n",
        "        # fit scaler\n",
        "        # features = pd.DataFrame(scaler.fit_transform(df[df.columns]), columns=df.columns)\n",
        "        features = df\n",
        "        features.index = target.index\n",
        "        return features\n",
        "\n",
        "    def create_ts_features(self, data):\n",
        "\n",
        "        def get_shift(row):\n",
        "            \"\"\"\n",
        "            3 shifts per day of 8 hours\n",
        "            \"\"\"\n",
        "            if 6 <= row.hour <= 14:\n",
        "                return 2\n",
        "            elif 15 <= row.hour <= 22:\n",
        "                return 3\n",
        "            else:\n",
        "                return 1\n",
        "\n",
        "        data.index = pd.to_datetime(data.index)\n",
        "        features = pd.DataFrame()\n",
        "        # features[\"hour\"] = data.index.hour\n",
        "        features[\"weekday\"] = data.index.weekday\n",
        "        features[\"dayofyear\"] = data.index.dayofyear\n",
        "        features[\"is_weekend\"] = data.index.weekday.isin([5, 6]).astype(np.int32)\n",
        "        # features[\"weekofyear\"] = data.index.isocalendar\n",
        "        features[\"month\"] = data.index.month\n",
        "        features[\"season\"] = (data.index.month % 12 + 3) // 3\n",
        "        features[\"shift\"] = pd.Series(data.index.map(get_shift))\n",
        "        features[\"energy use\"] = data.values\n",
        "        features.index = data.index\n",
        "        print(features)\n",
        "        return features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Packs features and target tensors\"\"\"\n",
        "        index = self.ids[idx]\n",
        "        features = self.data.loc[index]\n",
        "        lags = self.create_lag(features, lags=range(1, self.window_size + 1), thres=0.2)\n",
        "        ts = self.create_ts_features(features)\n",
        "        features_ = ts.join(lags, how=\"outer\").dropna()\n",
        "        target = features_[features_.index > features.index[self.window_size]][\"energy use\"]\n",
        "        features_ = features_[:-1]\n",
        "        # features_ = features_[features_.index < features_.index[-(self.window_size+1)]]\n",
        "        # return features_, target\n",
        "        return torch.tensor(features_.values), torch.tensor(target.values)"
      ],
      "metadata": {
        "id": "WqIawFqD345y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset('train.csv', frequency= \"D\", window_size= 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek3fBUE34P93",
        "outputId": "ecb98856-d16c-442f-d35c-f64bc6f7e92c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Dataset at 0x7fef22b290d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRjEmbPQ4Tnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}